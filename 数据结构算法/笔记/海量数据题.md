## 思想

    1.HASH  可以把相同的对象分片到同一个文件中

    2.分治   要找到分治的依据  

    3.位图
        1.位图法：bitmap，就是用每一位来存放某种状态，适用于大规模数据，但数据状态又不是很多的情况。通常是用来判断某个数据存不存在的。

        2.使用场景：

            1.排序  假设我们要对0-7内的5个元素(4,7,2,5,3)排序。那么我们就可以采用Bit-map的方法来达到排序的目的。要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0，然后把4 7 2 5 3位置上的0置为1  再遍历这个bitmap 把为1的index输出 则达到排序目的

            2.把num先/8在再%8得到index  在把num[index]|1 置为1 

        3.位图要排序所有int整数的话需要2^32个bit = 500M

        4，适用于排序，判断数字重复


## 大量URL中找到相同的URL    [hash分治 hashset]

    1.题目描述：
        给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。
    
    2.思路：
        一次性放入内存 肯定放不下 先遍历a 把a中URL%1000 分别放到1000个小文件中(a0...a999) 
        b同理 (b0...b999) 这样划分文件的好处和a0中URL相等的必然在b0中(因为hashcode相等) 
        所以再遍历a0 把所有url加入hashset 再遍历b0 如果在set 则记录下这个url 
        直到遍历完a999 b999


## 海量数据找中位数    [两堆   按二进制最高位分治]

    1.题目描述：
        从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。
    
    2.思路1： 双堆法

        1.维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数小于等于小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。

        若数据总数为偶数，当这两个堆建好之后，中位数就是这两个堆顶元素的平均值。当数据总数为奇数时，根据两个堆的大小，中位数一定在数据多的堆的堆顶。

        2.过程
            1.左边大根堆，右边小根堆。当前若新来的数字大于大根堆的堆顶，则加入右堆；否则加入左堆。
            2.若两堆数量差距大于1，将数量多的堆顶删除加入到另一个堆中
            3.重复以上过程

        3.缺点

            1.以上这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法适用于数据量较小的情况。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了
    
    3.思路2：分治法

        1.顺序读取这5亿个数，若其二进制的最高位是0，则放入文件F0中，最高位为1，就放入F1中。这样数据就被分为了两部分，而且F0中数小于F1.[最高位为符号位]

        2.第一次划分完后，中位数一定处于数量多的那个文件中。假定为F1，继续顺序读取F1中的数，用次高位将数据再分为二。 重复这个过程，直到文件可以被加载到内存
        中去。
  
## 大量数据中找到高频词      [分治+hashmap+堆]

    1.题目描述：
        有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。
    
    2.思路：  分治+hashmap+堆

        1.直接读取内存不够，所以先遍历文件，对词x用hash(x) % 5000分片到5000个文件中[这样保证了相同词在同一文件中]

        2.每个文件再遍历，用hashmap计数。每个文件构建一个大小为100的小顶堆，得到top100

        3.再把这5000个小顶堆拿出来，构建一个100的小顶堆求总的top100
    

## 如何找出某一天访问百度网站最多的 IP？  [分治+hashmap]

    1.题目描述
        现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。
    
    2.按hash取余分治 然后按hashmap计数 找到最高的次数 

## 如何在大量的数据中找出不重复的整数？

    1.题目描述
        1.在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。
    
    2.思路1： 分治
        1.和上述大量数据中找到高频词一样，先hash取模分治为不同文件，再在每个文件放入内存中找

    3.思路2:  位图法

        1. 用两个Bit来表示一个整数的状态  00为没出现过 01为出现一次 10为出现多次 要保存2^32个整数的话 需要1G内存

        2.遍历2.5亿个数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可
    