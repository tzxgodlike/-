## 思想

    1.HASH  可以把相同的对象分片到同一个文件中

    2.分治   要找到分治的依据  

    3.位图
        1.位图法：bitmap，就是用每一位来存放某种状态，适用于大规模数据，但数据状态又不是很多的情况。通常是用来判断某个数据存不存在的。

        2.使用场景：

            1.排序  假设我们要对0-7内的5个元素(4,7,2,5,3)排序。那么我们就可以采用Bit-map的方法来达到排序的目的。要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0，然后把4 7 2 5 3位置上的0置为1  再遍历这个bitmap 把为1的index输出 则达到排序目的

            2.把num先/8在再%8得到index  在把num[index]|1 置为1 

        3.位图要排序所有int整数的话需要2^32个bit = 500M

        4，适用于排序，判断数字重复 
            
            1.位图法使用与数字状态少的 如只判断出现或未出现  出现一次或多次这种 不适合计算出现的频次


## 大量URL中找到相同的URL    [hash分治 hashset]

    1.题目描述：
        给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。
    
    2.思路：
        一次性放入内存 肯定放不下 先遍历a 把a中URL%1000 分别放到1000个小文件中(a0...a999) 
        b同理 (b0...b999) 这样划分文件的好处和a0中URL相等的必然在b0中(因为hashcode相等) 
        所以再遍历a0 把所有url加入hashset 再遍历b0 如果在set 则记录下这个url 
        直到遍历完a999 b999


## 海量数据找中位数    [两堆   按二进制最高位分治]

    1.题目描述：
        从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 (N+1)/2 个数；当样本数为偶数时，中位数为 第 N/2 个数与第 1+N/2 个数的均值。
    
    2.思路1： 双堆法

        1.维护两个堆，一个大顶堆，一个小顶堆。大顶堆中最大的数小于等于小顶堆中最小的数；保证这两个堆中的元素个数的差不超过 1。

        若数据总数为偶数，当这两个堆建好之后，中位数就是这两个堆顶元素的平均值。当数据总数为奇数时，根据两个堆的大小，中位数一定在数据多的堆的堆顶。

        2.过程
            1.左边大根堆，右边小根堆。当前若新来的数字大于大根堆的堆顶，则加入右堆；否则加入左堆。
            2.若两堆数量差距大于1，将数量多的堆顶删除加入到另一个堆中
            3.重复以上过程

        3.缺点

            1.以上这种方法，需要把所有数据都加载到内存中。当数据量很大时，就不能这样了，因此，这种方法适用于数据量较小的情况。5 亿个数，每个数字占用 4B，总共需要 2G 内存。如果可用内存不足 2G，就不能使用这种方法了
    
    3.思路2：分治法

        1.顺序读取这5亿个数，若其二进制的最高位是0，则放入文件F0中，最高位为1，就放入F1中。这样数据就被分为了两部分，而且F0中数小于F1.[最高位为符号位]

        2.第一次划分完后，中位数一定处于数量多的那个文件中。假定为F1，继续顺序读取F1中的数，用次高位将数据再分为二。 重复这个过程，直到文件可以被加载到内存
        中去。
  
## 大量数据中找到高频词      [分治+hashmap+堆]

    1.题目描述：
        有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。
    
    2.思路：  分治+hashmap+堆

        1.直接读取内存不够，所以先遍历文件，对词x用hash(x) % 5000分片到5000个文件中[这样保证了相同词在同一文件中]

        2.每个文件再遍历，用hashmap计数。每个文件构建一个大小为100的小顶堆，得到top100

        3.再把这5000个小顶堆拿出来，构建一个100的小顶堆求总的top100
    

## 如何找出某一天访问百度网站最多的 IP？  [分治+hashmap]

    1.题目描述
        现有海量日志数据保存在一个超大文件中，该文件无法直接读入内存，要求从中提取某天访问百度次数最多的那个 IP。
    
    2.按hash取余分治 然后按hashmap计数 找到最高的次数 

## 如何在大量的数据中找出不重复的整数？

    1.题目描述
        1.在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。
    
    2.思路1： 分治
        1.和上述大量数据中找到高频词一样，先hash取模分治为不同文件，再在每个文件放入内存中找

    3.思路2:  位图法

        1. 用两个Bit来表示一个整数的状态  00为没出现过 01为出现一次 10为出现多次 要保存2^32个整数的话 需要1G内存

        2.遍历2.5亿个数，查看位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。遍历结束后，查看位图，把对应位是 01 的整数输出即可


## 如何查询最热门的n个查询串？
    
    1.题目描述  
        搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。
        假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。、
        请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）
    
    2.思路1：  分治

    3.思路2：  直接放HASHMAP 统计次数   然后用小顶堆
        虽然字符串总数比较多，但去重后不超过 300w，因此，可以考虑把所有字符串及出现次数保存在一个 HashMap 中，
        所占用的空间为 300w*(255+4)≈777M（其中，4表示整数占用的4个字节）。由此可见，1G 的内存空间完全够用。

    4.前缀树

        1.在遍历字符串时，在前缀树中查找，如果找到，则把结点中保存的字符串次数加 1，否则为这个字符串构建新结点，构建完成后把叶子结点中字符串的出现次数置为 1。

        最后依然使用小顶堆来对字符串的出现次数进行排序。

        2.前缀树经常被用来统计字符串的出现次数。它的另外一个大的用途是字符串查找，判断是否有重复的字符串等。


##  如何统计不同电话号码的个数？

    1.题目描述
        已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。

    2.思路：

        1.只需要判断是否重复 不需要计算重复次数  所以用位图

        2.8 位电话号码可以表示的号码个数为 10^8 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 100M。

        3.申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。


## 如何按照 query 的频度排序？

    1.题目描述
        有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。
    
    2.
        方法一：HashMap 法
            如果 query 重复率高，说明不同 query 总数比较小，可以考虑把所有的 query 都加载到内存中的 HashMap 中。接着就可以按照 query 出现的次数进行排序。

        方法二：分治法
        分治法需要根据数据量大小以及可用内存的大小来确定问题划分的规模。对于这道题，可以顺序遍历 10 个文件中的 query，通过 Hash 函数 hash(query) % 10 把这些 query 划分到 10 个小文件中。之后对每个小文件使用 HashMap 统计 query 出现次数，根据次数排序并写入到零外一个单独文件中。

        接着对所有文件按照 query 的次数进行排序，这里可以使用归并排序（由于无法把所有 query 都读入内存，因此需要使用外排序）。

            1.外部归并排序  小文件有序后  每次只需要把每个小文件的第一个数读进来比较 取最小的放入大文件
    
    3. 总结

        1.内存若够，直接读入进行排序；

        2.内存不够，先划分为小文件，小文件排好序后，整理使用外排序进行归并。

## 如何找出排名前 500 的数？  [topK  堆排序]

    1.题目描述
        有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 20*500 个数中找出前 500 的数？
    
    2.
        对于 TopK 问题，最常用的方法是使用堆排序。对本题而言，假设数组降序排列，可以采用以下方法：

        首先建立大顶堆，堆的大小为数组的个数，即为 20，把每个数组最大的值存到堆中。

        接着删除堆顶元素，保存到另一个大小为 500 的数组中，然后向大顶堆插入删除的元素所在数组的下一个元素。

        重复上面的步骤，直到删除完第 500 个元素，也即找出了最大的前 500 个数。
    
    3. 关键点在于删除堆顶后替补的数必须是对应的数组 

    4. 腾讯面试 ：  除了用堆还能用什么？
